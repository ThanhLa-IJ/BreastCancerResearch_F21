---
title: "AnalysisScript - Breast Cancer Wisconsin (Diagnostic)"
author: "Thanh La, Son Luong"
date: "10/17/2021"
output:
  pdf_document: default
  html_document: default
director: Dr. Katherine Shoemaker
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=F}
library(tidyverse)
library(reshape2)
library(reshape)
library(ggplot2)
library(GGally)
library(ISLR)
library(caret)
library(cowplot)
library(MASS)
library(dplyr)

```


```{r}
workfile <- read.csv("data.csv")
numeric_workfile <- workfile[,3:32 ]
```

# workfile Exploration

```{r}
colnames(workfile)
```

```{r}
summary(numeric_workfile)
all(is.na(workfile))
```

# workfile Visualization

# I. Relationship Between Variable

```{r}
group = NA
group[workfile$diagnosis == "B"] = 1
group[workfile$diagnosis == "M"] = 2


workfile %>% 
  select_if(is.numeric) %>%
  dplyr::select(contains("mean")) %>%
  pairs(col = c("blue", "red")[group], main = "The relationship between 'Mean' variable")

workfile %>% 
  select_if(is.numeric) %>% 
  dplyr::select(contains("SE")) %>% 
  pairs(col = c("blue", "red")[group], main = "The relationship between 'Standard Error' variable")

workfile %>% 
  select_if(is.numeric) %>% 
  dplyr::select(contains("worst")) %>% 
  pairs(col = c("blue", "red")[group], main = "The relationship between 'Worst' variable") 
```

# II. Differently Distributed Between Two Group of Diagnosis

# look at how the variables are differently distributed between the two groups

# these variables below are greatly different among 2 group of diagnosis

```{r}
ggpairs(workfile[,c(3:12,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
```
```{r}
ggpairs(workfile[,c(13:22,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
```
```{r}
ggpairs(workfile[,c(23:32,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
```

cor()#
cov()#
https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/cor

# III. Logistic Regression Model
```{r}
workfile$diagnosis = as.factor(workfile$diagnosis)
workfile = subset(workfile, select = -c(id))
```

```{r}
str(workfile)
```

```{r}
head(workfile)
```
# Apply Stepwise Regression to find Correlattion of variable

```{r, warning=F}
# backward stepwise regression
full_model = glm(diagnosis~., family = "binomial", data = workfile)
backward_model = step(full_model, direction = "backward")
```

```{r}
# forward stepwise regression
null_model = glm(diagnosis~1, family = "binomial", data = workfile)

forwar_model = step(null_model, 
                    scope = list(lower = formula(null_model),
                                 uper = formula(null_model)),
                    direction = "forward")
```


# Apply logistic regression to data 

```{r}
train_control = trainControl(method = "repeatedcv", number = 10, repeats = 20)
```

```{r, include = F, echo  =F}
# Set the train and test part of valiadation dataset
index_set = sample(2, nrow(workfile), replace = T, prob = c(0.7, 0.3))
train_workfile = workfile[index_set == 1,] 
test_workfile = workfile[index_set == 2,]
```

To make the logistic regression model more efficient (or improve the probability of the prediction), I will separate the characteristic variable to different part such as: size, shape, surface

+ Every variable
```{r}
by_all = function(workfile, train_control){
  workfile_glm = train(diagnosis~.,
                       data = workfile, 
                       trControl = train_control, 
                       method = "glm", 
                       family = binomial())
  return(workfile_glm)
}
```

+ Size: Radius, perimeter, area, compactness, fractal dimension

```{r}
by_size = function(workfile, train_control){
  workfile_glm = train(diagnosis~radius_mean + radius_se + radius_worst + 
                         perimeter_mean + perimeter_se + perimeter_worst + 
                         area_mean + area_se + area_worst + 
                         compactness_mean + compactness_se + compactness_worst + 
                         fractal_dimension_mean +  fractal_dimension_se + fractal_dimension_worst
                       ,data = workfile, 
                       trControl = train_control, 
                       method = "glm", 
                       family = binomial())
  
  return(workfile_glm)
}
```

+ Shape, surface: texture, smoothness, concavity, concave.points, symmetry, fractal dimension

```{r}
by_shape = function(workfile, train_control){
  workfile_glm = train(diagnosis~ texture_mean + texture_se + texture_worst + 
                         smoothness_mean + smoothness_se + smoothness_worst + 
                         concavity_mean + concavity_se + concavity_worst + 
                         concave.points_mean + concave.points_se + concave.points_worst + 
                         symmetry_mean + symmetry_se + symmetry_worst + 
                         fractal_dimension_mean +  fractal_dimension_se + fractal_dimension_worst, 
                       data = workfile,
                       method = "glm", 
                       family = binomial())
  return(workfile_glm)
}

```

+ Stepwise Backward suggest

```{r}
by_stepwise_backward = function(workfile, train_control){
  workfile_glm = train(diagnosis ~ radius_mean + texture_mean + area_mean + smoothness_mean + 
    compactness_mean + concavity_mean + concave.points_mean + 
    symmetry_mean + fractal_dimension_mean + perimeter_se + area_se + 
    smoothness_se + compactness_se + concavity_se + concave.points_se + 
    symmetry_se + fractal_dimension_se + radius_worst + texture_worst + 
    perimeter_worst + area_worst + concavity_worst + symmetry_worst + 
    fractal_dimension_worst, 
                       data = workfile,
                       method = "glm", 
                       family = binomial())
  
  return(workfile_glm)
}
```

+ Stepwise Forward Suggest

```{r}

```


#  Build a Train - Test of Logistic Regression 

Train - test by size

```{r, warning=F}
workfile_glm = by_all(workfile, train_control)
workfile_glm
summary(workfile_glm)
```

```{r}
# now ewe predict on the test data
y_hat = predict(workfile_glm, newdata = workfile)
confusionMatrix(y_hat, workfile$diagnosis)

```

```{r}
y_hat = as.vector(y_hat)
diagnosis = as.vector(test_workfile$diagnosis)

check_table = data.frame(ML_result = y_hat, correct_result = diagnosis ) %>% 
  mutate(checked = ifelse(ML_result == correct_result, "Yes", "No"))
```




















