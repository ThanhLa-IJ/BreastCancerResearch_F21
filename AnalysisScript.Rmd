---
title: "AnalysisScript - Breast Cancer Wisconsin (Diagnostic)"
author: "Thanh La, Son Luong"
date: "10/17/2021"
output:
  pdf_document: default
  html_document: default
director: Dr. Katherine Shoemaker
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=F}
library(tidyverse)
library(reshape2)
library(reshape)
library(ggplot2)
library(GGally)
library(ISLR)
library(caret)
library(cowplot)
library(MASS)
library(dplyr)
library(leaps)
library(ggeffects)
library(patchwork)
```


```{r}
workfile <- read.csv("data.csv")
numeric_workfile <- workfile[,3:32 ]

#workfile = workfile %>% mutate(diagnosis = case_when(diagnosis == "B" ~ 0,   
 #                                                    diagnosis == "M" ~ 1))

  
```

# workfile Exploration

```{r, include=F}
colnames(workfile)
```

```{r, include=F}
summary(numeric_workfile)
all(is.na(workfile))
```

# workfile Visualization

# I. Relationship Between Variable

```{r, include = F}
group = NA
group[workfile$diagnosis == "B"] = 1
group[workfile$diagnosis == "M"] = 2


workfile %>% 
  select_if(is.numeric) %>%
  dplyr::select(contains("mean")) %>%
  pairs(col = c("blue", "red")[group], main = "The relationship between 'Mean' variable")

workfile %>% 
  select_if(is.numeric) %>% 
  dplyr::select(contains("SE")) %>% 
  pairs(col = c("blue", "red")[group], main = "The relationship between 'Standard Error' variable")

workfile %>% 
  select_if(is.numeric) %>% 
  dplyr::select(contains("worst")) %>% 
  pairs(col = c("blue", "red")[group], main = "The relationship between 'Worst' variable") 
```

# II. Differently Distributed Between Two Group of Diagnosis

# look at how the variables are differently distributed between the two groups

# these variables below are greatly different among 2 group of diagnosis

```{r, include=F}
ggpairs(workfile[,c(3:12,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
```
```{r, include=F}
ggpairs(workfile[,c(13:22,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
```
```{r}
ggpairs(workfile[,c(23:32,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))+
theme(plot.title=element_text(face='bold',color='black',hjust=0.5,size=12))
```


# III. Logistic Regression Model
```{r, include=F}
workfile$diagnosis = as.factor(workfile$diagnosis)
workfile = subset(workfile, select = -c(id))
```

```{r, include=F}
str(workfile)
```

```{r, include=F}
head(workfile)
```
# Apply Stepwise Regression to find Correlattion of variable

```{r, warning=F, include = F }
# backward stepwise regression
full_model = glm(diagnosis~., family = "binomial", data = workfile)
backward_model = step(full_model, direction = "backward")
```

```{r, warning=F, include = F}
# forward stepwise regression
#Forward
forward_glm <- glm (diagnosis ~1, data = workfile, family ="binomial")
step(forward_glm, direction = "forward",scope=formula(full_model))
```

```{r, warning=F, include=F}
#Both direction
step(forward_glm, direction = "both",scope=formula(full_model))
```


# Apply logistic regression to data 
```{r, include = F}
# Set the train and test part of valiadation dataset
index_set = sample(2, nrow(workfile), replace = T, prob = c(0.7, 0.3))
train_workfile = workfile[index_set == 1,] 
test_workfile = workfile[index_set == 2,]
```

```{r}
train_control = trainControl(method = "LOOCV", number = nrow(train_workfile))
```


+ Stepwise Backward suggest

```{r}
# glm(diagnosis~.)
by_stepwise_backward = function(workfile, train_control){
  workfile_glm = train(diagnosis ~ radius_mean + texture_mean + area_mean + smoothness_mean + 
    compactness_mean + concavity_mean + concave.points_mean + 
    symmetry_mean + fractal_dimension_mean + perimeter_se + area_se + 
    smoothness_se + compactness_se + concavity_se + concave.points_se + 
    symmetry_se + fractal_dimension_se + radius_worst + texture_worst + 
    perimeter_worst + area_worst + concavity_worst + symmetry_worst + 
    fractal_dimension_worst, 
                       data = workfile,
                       trControl = train_control,
                       method = "glm", 
                       family = binomial())
  
  return(workfile_glm)
}
```

+ Stepwise Forward Suggest

```{r}
by_stepwise_forward = function(workfile, train_control){
  workfile_glm = train(diagnosis ~ perimeter_worst + smoothness_worst + 
    texture_worst + radius_se + symmetry_worst + compactness_se + 
    concavity_mean + texture_se + area_se + concave.points_worst, 
                       data = workfile,
                       trControl = train_control,
                       method = "glm", 
                       family = binomial())
  
  return(workfile_glm)
}
```

+ Both direction suggest
```{r}
by_stepwise_both = function(workfile, train_control){
  workfile_glm = train(diagnosis ~ smoothness_worst + texture_worst + 
    symmetry_worst + compactness_se + concavity_mean + texture_se + 
    area_se + concave.points_worst + area_worst, 
                       data = workfile,
                       method = "glm",
                       trControl = train_control,
                       family = binomial())
  
  return(workfile_glm)
}
```
#  Build a Train - Test of Logistic Regression 
 + Predicting _ forward

```{r, warning=F}
workfile_glm = by_stepwise_forward(train_workfile, train_control)
workfile_glm
summary(workfile_glm)
```

```{r}
# now ewe predict on the test data
y_hat = predict(workfile_glm, newdata = test_workfile)
y_hat_prob = predict(workfile_glm, newdata = test_workfile, type = "prob")
test_workfile$predict_diagnosis = y_hat
test_workfile$predict_diagnosis_prob = y_hat_prob$M

```

```{r}
confusionMatrix(y_hat, test_workfile$diagnosis)
```

```{r}
test_workfile$predict_diagnosis = y_hat
test_workfile = test_workfile %>% dplyr::select(diagnosis, predict_diagnosis, predict_diagnosis_prob, everything())
head(test_workfile)
```

```{r}
plot(as.numeric(diagnosis)-1~ texture_se, data = train_workfile, col = "blue")
points(predict_diagnosis_prob~ texture_se, data = test_workfile, col = predict_diagnosis)
abline(h = 0.5, lty = 3)

```

```{r, fig.width=12, fig.height=6}

plts = lapply(names(workfile_glm$finalModel$coefficients)[-1],function(i){
       return(plot(ggpredict(workfile_glm$finalModel,i)))
       })

wrap_plots(plts)
```


+ Predicting _ backward

```{r, warning=F}
workfile_glm = by_stepwise_backward(train_workfile, train_control)
workfile_glm
summary(workfile_glm)
```

```{r}
# now ewe predict on the test data
y_hat = predict(workfile_glm, newdata = test_workfile)
y_hat_prob = predict(workfile_glm, newdata = test_workfile, type = "prob")
test_workfile$predict_diagnosis = y_hat
test_workfile$predict_diagnosis_prob = y_hat_prob$M

```

```{r}
confusionMatrix(y_hat, test_workfile$diagnosis)
```

```{r}
test_workfile$predict_diagnosis = y_hat
test_workfile = test_workfile %>% dplyr::select(diagnosis, predict_diagnosis, predict_diagnosis_prob, everything())
head(test_workfile)
```

```{r}
plot(as.numeric(diagnosis)-1~ perimeter_mean, data = train_workfile, col = "blue")
points(predict_diagnosis_prob~ perimeter_mean, data = test_workfile, col = predict_diagnosis)
abline(h = 0.5, lty = 3)

```

```{r, fig.width=12, fig.height=6}

plts = lapply(names(workfile_glm$finalModel$coefficients)[-1],function(i){
       return(plot(ggpredict(workfile_glm$finalModel,i)))
       })

wrap_plots(plts)
```
