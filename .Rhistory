decision=numeric(0)
N=10^4
n=5
alp= 0.07 #alpha
for(i in 1:N){
dat=rnorm(n,4,1)
decision[i]  = t.test(dat, mu=4,  alternative="two.sided")$p.value
}
sum(ifelse(decision <= alp,1,0))/N
library(TeachingDemos)
decision=numeric(0)
N=10^4
n=5
alp= 0.07 #alpha
for(i in 1:N){
dat=rnorm(n,4,1)
decision[i]  = t.test(dat, mu=4,  alternative="two.sided")$p.value
}
sum(ifelse(decision <= alp,1,0))/N
library(TeachingDemos)
decision=numeric(0)
N=10^4
n=5
alp= 0.05 #alpha
for(i in 1:N){
dat=rnorm(n,100,1)
decision[i]  = z.test(dat, mu <= 100,stdev=1,  alternative="two.sided")$p.value
}
sum(ifelse(decision <= alp,1,0))/N
library(TeachingDemos)
decision=numeric(0)
N=10^4
n=5
alp= 0.05 #alpha
for(i in 1:N){
dat=rnorm(n,100,1)
decision[i]  = z.test(dat, mu < 100,stdev=1,  alternative="two.sided")$p.value
}
sum(ifelse(decision <= alp,1,0))/N
library(TeachingDemos)
decision=numeric(0)
N=10^4
n=5
alp= 0.05 #alpha
for(i in 1:N){
dat=rnorm(n,100,1)
decision[i]  = z.test(dat, mu < 100,stdev=1,  alternative="two.sided")$p.value
}
sum(ifelse(decision <= alp,1,0))/N
library(TeachingDemos)
decision=numeric(0)
N=10^4
n=5
alp= 0.05 #alpha
for(i in 1:N){
dat=rnorm(n,100,1)
decision[i]  = z.test(dat, mu > 100,stdev=1,  alternative="two.sided")$p.value
}
sum(ifelse(decision <= alp,1,0))/N
knitr::opts_chunk$set(echo = TRUE)
str(data)
summary(numeric_data)
str(data)
summary(data)
data <- read.csv("data.csv")
numeric_data <- data[,3:32 ]
library(tidyverse)
library(reshape2)
library(reshape)
library(ggplot2)
library(GGally)
data <- read.csv("data.csv")
numeric_data <- data[,3:32 ]
str(data)
summary(data)
head(data)
all(is.na(data))
ggpairs(data[,c(3:12,2)], histogram = T, aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))
ggpairs(data[,c(3:12,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
View(Default)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ISLR)
library(resampledata)
# Logistic Regression
data(Default)
glimpse(Default)
default_lm <- glm(default ~ balance, family = "binomial", data = Default)
# Logistic Regression
data(Default)
glimpse(Default)
default_lm <- glm(default ~ balance, family = "binomial", data = Default)
default_lm
# Logistic Regression
data(Default)
# glimpse(Default)
default_lm <- glm(default ~ balance, family = "binomial", data = Default)
default_lm
# summary(default_lm)
y_hatpredict(default_lm, data = Default, type = "response")
# summary(default_lm)
y_hat = predict(default_lm, data = Default, type = "response")
# summary(default_lm)
y_hat = predict(default_lm, data = Default, type = "response")
y_hat
# summary(default_lm)
y_hat = predict(default_lm, data = Default, type = "response")
y_hat
predicted_class = vector(length = length(yhat))
# summary(default_lm)
y_hat = predict(default_lm, data = Default, type = "response")
y_hat
predicted_class = vector(length = length(y_hat))
predicted_class[y_hat > 0.5] = "yes"
predicted_class[y_hat < 0.5] = "no"
# summary(default_lm)
y_hat = predict(default_lm, data = Default, type = "response")
head(y_hat)
predicted_class = vector(length = length(y_hat))
predicted_class[y_hat > 0.5] = "yes"
predicted_class[y_hat < 0.5] = "no"
predicted_class = as.factor(predicted_class)
#how do we know 1 is no and 2 is yes
levels(Default$default)
levels(predicted_class)
x = cbind(as.factor(predicted_class), Default$default)
View(x)
# summary(default_lm)
y_hat = predict(default_lm, data = Default, type = "response")
head(y_hat)
predicted_class = vector(length = length(y_hat))
predicted_class[y_hat > 0.5] = "yes"
predicted_class[y_hat < 0.5] = "no"
predicted_class = as.factor(predicted_class)
#how do we know 1 is no and 2 is yes
levels(Default$default)
levels(predicted_class)
x = cbind(predicted = as.factor(predicted_class), default = Default$default)
#we sum up the logical/boolean vecotr here to see how many times our model was right
sum(predicted_class = Default$default)
#we sum up the logical/boolean vecotr here to see how many times our model was right
sum(predicted_class == Default$default)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ISLR)
library(resampledata)
data(Default)
# glimpse(Default)
default_lm <- glm(default ~ balance, family = "binomial", data = Default)
default_lm
# summary(default_lm)
y_hat = predict(default_lm, data = Default, type = "response")
head(y_hat)
predicted_class = vector(length = length(y_hat))
predicted_class[y_hat > 0.5] = "yes"
predicted_class[y_hat < 0.5] = "no"
predicted_class = as.factor(predicted_class)
#how do we know 1 is no and 2 is yes
levels(Default$default)
levels(predicted_class)
x = cbind(as.factor(predicted_class), Default$default)
#we sum up the logical/boolean vecotr here to see how many times our model was right
sum(predicted_class == Default$default)
penguins
library(palmerpenguins)
penguins
my_penguins = penguins %>% filter(species %in% c("Andelie", "Gentoo"))
my_penguins_model = glm(species ~ bill_length_mm + bil_depth_mm + body_mass_g, data = my_penguins)
my_penguins = penguins %>% filter(species %in% c("Andelie", "Gentoo"))
my_penguins_model = glm(species ~ bill_length_mm + bill_depth_mm + body_mass_g, data = my_penguins)
my_penguins = penguins %>% na.omit()%>% filter(species %in% c("Andelie", "Gentoo"))
my_penguins_model = glm(species ~ bill_length_mm + bill_depth_mm + flipper_length_mm+ body_mass_g, data = my_penguins)
my_penguins = penguins %>% na.omit()%>% filter(species %in% c("Andelie", "Gentoo"))
my_penguins_model = glm(species ~ bill_length_mm + bill_depth_mm + flipper_length_mm+ body_mass_g, family = "binomial", data = my_penguins)
View(my_penguins_model)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(reshape2)
library(reshape)
library(ggplot2)
library(GGally)
data <- read.csv("data.csv")
setwd("C:/Users/Thanh La/Downloads/Study/UHD/5.fall_2021/SA/research/BreastCancerResearch_F21")
data <- read.csv("data.csv")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(reshape2)
library(reshape)
library(ggplot2)
library(GGally)
data <- read.csv("data.csv")
numeric_data <- data[,3:32 ]
colnames(data)
summary(numeric_data)
all(is.na(data))
#mean of each varible, group by diagnosis
data_mean <- data %>% group_by(diagnosis)%>%summarise_at(vars(-id),funs(mean(., na.rm=TRUE)))
group = NA
group[data$diagnosis == "B"] = 1
group[data$diagnosis == "M"] = 2
data %>%
select_if(is.numeric) %>%
select(contains("mean")) %>%
pairs(col = c("blue", "red")[group], main = "The relationship between 'Mean' variable")
data %>%
select_if(is.numeric) %>%
select(contains("SE")) %>%
pairs(col = c("blue", "red")[group], main = "The relationship between 'Standard Error' variable")
data %>%
select_if(is.numeric) %>%
select(contains("worst")) %>%
pairs(col = c("blue", "red")[group], main = "The relationship between 'Worst' variable")
ggpairs(data[,c(3:12,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))
data = data %>%
mutate(FT_diagnosis = case_when(diagnosis == "B" ~ 2,
diagnosis == "M" ~1)) %>%
select(id, diagnosis, FT_diagnosis, everything())
data <- read.csv("data.csv")
numeric_data <- data[,3:32 ]
library(tidyverse)
library(reshape2)
library(reshape)
library(ggplot2)
library(GGally)
library(ISLR)
data_glm = glm(data~diagnosis, family = "binomial", data = data)
data <- read.csv("data.csv")
numeric_data <- data[,3:32 ]
data_glm = glm(data~diagnosis, family = "binomial", data = data)
data_glm = glm(data ~ diagnosis, family = "binomial", data = data)
data_glm = glm(data ~ diagnosis, family = "binomial", data)
workfile <- read.csv("data.csv")
numeric_workfile <- workfile[,3:32 ]
colnames(workfile)
summary(numeric_workfile)
all(is.na(workfile))
#mean of each varible, group by diagnosis
workfile_mean <- workfile %>% group_by(diagnosis)%>%summarise_at(vars(-id),funs(mean(., na.rm=TRUE)))
group = NA
group[workfile$diagnosis == "B"] = 1
group[workfile$diagnosis == "M"] = 2
workfile %>%
select_if(is.numeric) %>%
select(contains("mean")) %>%
pairs(col = c("blue", "red")[group], main = "The relationship between 'Mean' variable")
workfile %>%
select_if(is.numeric) %>%
select(contains("SE")) %>%
pairs(col = c("blue", "red")[group], main = "The relationship between 'Standard Error' variable")
workfile %>%
select_if(is.numeric) %>%
select(contains("worst")) %>%
pairs(col = c("blue", "red")[group], main = "The relationship between 'Worst' variable")
ggpairs(workfile[,c(3:12,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))
workfile_glm = glm(workfile ~ diagnosis, family = "binomial", data = workfile)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(reshape2)
library(reshape)
library(ggplot2)
library(GGally)
library(ISLR)
workfile <- read.csv("data.csv")
numeric_workfile <- workfile[,3:32 ]
#mean of each varible, group by diagnosis
workfile_mean <- workfile %>% group_by(diagnosis)%>%summarise_at(vars(-id),funs(mean(., na.rm=TRUE)))
View(workfile)
workfile_glm = glm(default ~ diagnosis, family = "binomial", data = workfile)
ggpairs(workfile[,c(3:12,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))
ggpairs(workfile[,c(3:12,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))
workfile_glm = glm(diagnosis ~ radius_mean+texture_mean+area_mean+smoothness_mean+compactness_mean+symmetric_mean+fractal_dimension_mean, family = "binomial", data = workfile)
workfile_glm = glm(diagnosis ~ radius_mean+texture_mean+area_mean+smoothness_mean+compactness_mean+symmetry_mean+fractal_dimension_mean, family = "binomial", data = workfile)
knitr::opts_chunk$set(echo = TRUE)
# install.packages("palmerpenguins")
library(palmerpenguins)
penguins
my_penguin <- penguins %>% na.omit() %>% filter(species %in% c("Adelie", "Chinstrap"))
## with multiple variables, pick a few and then use the accuracy of the model to find a good combination of variables
## you will need to use "as.factor" on the y to change it from a character vector to a factor
## Or use strings.as.Factors == T
####
my_penguin_model <- glm(species ~ bill_length_mm + bill_depth_mm + flipper_length_mm  , family = "binomial",  data = my_penguin)
summary(my_penguin_model)
## the output of this function is the *probability* of being in the second class, in this case, Chinstrap
y_hat <- predict(my_penguin_model, data = my_penguin, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "Chinstrap"
predicted_class[y_hat <= 0.5] <- "Adelie"
predicted_class <- as.factor(predicted_class)
## table of my predictions vs the truth
table(predicted_class, my_penguin$species)
## accuracy: num of times the model is right / total number of times
(145 + 66) / length(predicted_class)
## start with one variable
## function: glm (stands for general linear model)
## "formula" y ~ x (dependent/outcome/classes ~ variables)
## family = "binomial" is how we make it a *logistic* regression
## data = our_data_frame
default_lm <- glm(default ~ balance, family = "binomial", data = Default)
summary(default_lm)
# the output of our model:
# the probability that that subject will default, P(Default | balance information)
y_hat <- predict(default_lm, data = Default, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "Yes"
predicted_class[y_hat <= 0.5] <- "No"
predicted_class <- as.factor(predicted_class)
## how do we know 1 is no and 2 is yes:
levels(Default$default)
levels(predicted_class)
x <- cbind(predicted_class, Default$default)
## we sum up the logical/Boolean vector here to see how many times our model was right
sum(predicted_class == Default$default)
## divide that by the number of observations to see our accuracy
sum(predicted_class == Default$default) / length(predicted_class) * 100
## Note: this is the accuracy on data used to build/create the model.
## we're going to be interested in how well the model works on NEW data.
library(ISLR)
library(tidyverse)
data(Default)
glimpse(Default)
## start with one variable
## function: glm (stands for general linear model)
## "formula" y ~ x (dependent/outcome/classes ~ variables)
## family = "binomial" is how we make it a *logistic* regression
## data = our_data_frame
default_lm <- glm(default ~ balance, family = "binomial", data = Default)
summary(default_lm)
# the output of our model:
# the probability that that subject will default, P(Default | balance information)
y_hat <- predict(default_lm, data = Default, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "Yes"
predicted_class[y_hat <= 0.5] <- "No"
predicted_class <- as.factor(predicted_class)
## how do we know 1 is no and 2 is yes:
levels(Default$default)
levels(predicted_class)
x <- cbind(predicted_class, Default$default)
## we sum up the logical/Boolean vector here to see how many times our model was right
sum(predicted_class == Default$default)
## divide that by the number of observations to see our accuracy
sum(predicted_class == Default$default) / length(predicted_class) * 100
## Note: this is the accuracy on data used to build/create the model.
## we're going to be interested in how well the model works on NEW data.
sum(predicted_class == Default$default)
# the output of our model:
# the probability that that subject will default, P(Default | balance information)
y_hat <- predict(default_lm, data = Default, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "Yes"
predicted_class[y_hat <= 0.5] <- "No"
predicted_class <- as.factor(predicted_class)
# the output of our model:
# the probability that that subject will default, P(Default | balance information)
y_hat <- predict(default_lm, data = Default, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "Yes"
predicted_class[y_hat <= 0.5] <- "No"
predicted_class <- as.factor(predicted_class)
predicted_class
# install.packages("palmerpenguins")
library(palmerpenguins)
penguins
my_penguin <- penguins %>% na.omit() %>% filter(species %in% c("Adelie", "Chinstrap"))
## with multiple variables, pick a few and then use the accuracy of the model to find a good combination of variables
## you will need to use "as.factor" on the y to change it from a character vector to a factor
## Or use strings.as.Factors == T
####
my_penguin_model <- glm(species ~ bill_length_mm + bill_depth_mm + flipper_length_mm  , family = "binomial",  data = my_penguin)
summary(my_penguin_model)
## the output of this function is the *probability* of being in the second class, in this case, Chinstrap
y_hat <- predict(my_penguin_model, data = my_penguin, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "Chinstrap"
predicted_class[y_hat <= 0.5] <- "Adelie"
predicted_class <- as.factor(predicted_class)
## table of my predictions vs the truth
table(predicted_class, my_penguin$species)
## accuracy: num of times the model is right / total number of times
(145 + 66) / length(predicted_class)
workfile_glm = glm(diagnosis ~ ., family = "binomial", data = workfile)
workfile$diagnosis = as.factor(workfile$diagnosis)
temp_workfile = subset(workfile, select = -c(id))
workfile_glm = glm(diagnosis ~ ., family = "binomial", data = temp_workfile)
summary(workfile_glm)
workfile$diagnosis = as.factor(workfile$diagnosis)
temp_workfile = subset(workfile, select = -c(id))
temp_workfile = temp_workfile %>% select(contains("mean"))
workfile_glm = glm(diagnosis ~ ., family = "binomial", data = temp_workfile)
workfile$diagnosis = as.factor(workfile$diagnosis)
temp_workfile = subset(workfile, select = -c(id))
temp_workfile = temp_workfile %>% select(diagnosis, contains("mean"))
workfile_glm = glm(diagnosis ~ ., family = "binomial", data = temp_workfile)
summary(workfile_glm)
y_hat = predict(workfile_glm, data = temp_workfile, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "Yes"
predicted_class[y_hat <= 0.5] <- "No"
predicted_class <- as.factor(predicted_class)
## how do we know 1 is no and 2 is yes:
levels(Default$default)
levels(predicted_class)
x <- cbind(predicted_class, temp_workfile$diagnosis)
## we sum up the logical/Boolean vector here to see how many times our model was right
sum(predicted_class == temp_workfile$diagnosis)
## how do we know 1 is no and 2 is yes:
levels(Default$default)
levels(predicted_class)
x <- cbind(predicted_class, temp_workfile$diagnosis)
## we sum up the logical/Boolean vector here to see how many times our model was right
sum(predicted_class == temp_workfile$diagnosis)
y_hat = predict(workfile_glm, data = temp_workfile, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "Yes"
predicted_class[y_hat <= 0.5] <- "No"
predicted_class <- as.factor(predicted_class)
length(predicted_class)
length(temp_workfile)
y_hat = predict(workfile_glm, data = temp_workfile, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "Yes"
predicted_class[y_hat <= 0.5] <- "No"
predicted_class <- as.factor(predicted_class)
length(predicted_class)
nrow(temp_workfile)
y_hat = predict(workfile_glm, data = temp_workfile, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "Yes"
predicted_class[y_hat <= 0.5] <- "No"
predicted_class <- as.factor(predicted_class)
## how do we know 1 is no and 2 is yes:
levels(Default$default)
levels(predicted_class)
x <- cbind(predicted_class, temp_workfile$diagnosis)
## we sum up the logical/Boolean vector here to see how many times our model was right
predicted_class == temp_workfile$diagnosis
y_hat = predict(workfile_glm, data = temp_workfile, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "Yes"
predicted_class[y_hat <= 0.5] <- "No"
predicted_class <- as.factor(predicted_class)
y_hat = predict(workfile_glm, data = temp_workfile, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "Yes"
predicted_class[y_hat <= 0.5] <- "No"
predicted_class <- as.factor(predicted_class)
table(predicted_class, temp_workfile$diagnosis)
## how do we know 1 is no and 2 is yes:
levels(Default$default)
levels(predicted_class)
x <- cbind(predicted_class, temp_workfile$diagnosis)
## we sum up the logical/Boolean vector here to see how many times our model was right
sum(predicted_class == temp_workfile$diagnosis)
## how do we know 1 is no and 2 is yes:
levels(temp_workfile$diagnosis)
levels(predicted_class)
x <- cbind(predicted_class, temp_workfile$diagnosis)
## we sum up the logical/Boolean vector here to see how many times our model was right
sum(predicted_class == temp_workfile$diagnosis)
y_hat = predict(workfile_glm, data = temp_workfile, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "B"
predicted_class[y_hat <= 0.5] <- "M"
predicted_class <- as.factor(predicted_class)
table(predicted_class, temp_workfile$diagnosis)
## how do we know 1 is no and 2 is yes:
levels(temp_workfile$diagnosis)
levels(predicted_class)
x <- cbind(predicted_class, temp_workfile$diagnosis)
## we sum up the logical/Boolean vector here to see how many times our model was right
sum(predicted_class == temp_workfile$diagnosis)
## divide that by the number of observations to see our accuracy
sum(predicted_class == temp_workfile$diagnosis) / length(predicted_class) * 100
## Note: this is the accuracy on data used to build/create the model.
## we're going to be interested in how well the model works on NEW data.
## how do we know 1 is no and 2 is yes:
levels(temp_workfile$diagnosis)
levels(predicted_class)
x <- cbind(predicted_class, temp_workfile$diagnosis)
## we sum up the logical/Boolean vector here to see how many times our model was right
sum(predicted_class == temp_workfile$diagnosis)
## divide that by the number of observations to see our accuracy
sum(predicted_class == temp_workfile$diagnosis) / length(predicted_class) * 100
## Note: this is the accuracy on data used to build/create the model.
## we're going to be interested in how well the model works on NEW data.
ggpairs(workfile[,c(13:22,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))
ggpairs(workfile[,c(13:22,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))
ggpairs(workfile[,c(23:32,2)], aes(color=diagnosis, alpha=0.5), lower=list(continuous="smooth"))
workfile$diagnosis = as.factor(workfile$diagnosis)
temp_workfile = subset(workfile, select = -c(id))
#temp_workfile = temp_workfile %>% select(diagnosis, contains("mean"))
workfile_glm = glm(diagnosis ~ ., family = "binomial", data = temp_workfile)
summary(workfile_glm)
y_hat = predict(workfile_glm, data = temp_workfile, type = "response")
predicted_class <- vector(length = length(y_hat))
predicted_class[y_hat > 0.5] <- "B"
predicted_class[y_hat <= 0.5] <- "M"
predicted_class <- as.factor(predicted_class)
table(predicted_class, temp_workfile$diagnosis)
## how do we know 1 is no and 2 is yes:
levels(temp_workfile$diagnosis)
levels(predicted_class)
x <- cbind(predicted_class, temp_workfile$diagnosis)
## we sum up the logical/Boolean vector here to see how many times our model was right
sum(predicted_class == temp_workfile$diagnosis)
## divide that by the number of observations to see our accuracy
sum(predicted_class == temp_workfile$diagnosis) / length(predicted_class) * 100
## Note: this is the accuracy on data used to build/create the model.
## we're going to be interested in how well the model works on NEW data.
